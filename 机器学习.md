

# 统计学习及监督学习概论

统计学习方法可以概括如下：

从给定的、有限的、用于学习的训练数据(training data)集合出发，假设数据是独立同分布产生的；并且假设要学习的模型属于某个函数的集合，称为假设空间(hypothesis)；应用某个评价标准(evaluation)，从假设空间中选取一个最优模型，使它对已知的训练数据及未知的测试数据(test data)在给定的评价准则下有最优的预测；最优模型的选取由算法实现.。这样，统计学习方法包括模型的假设空间、模型选择的准则以及模型学习的算法，统称其为统计学习的三要素，简称为模型(model)、策略(strategy)和算法(algorithm)。

实现统计学习方法的步骤如下：

(1)：得到一个有限的训练数据集合；

(2)：确定包含所有可能的模型的假设空间，即学习模型的集合；

(3)：确定模型选择的准则，即学习的策略；

(4)：实现求解最优模型的算法，即学习的算法；

(5)：通过学习方法选择最优模型；

(6)：利用学习的最优模型对新数据进行预测或分析。

### 监督学习

输入空间：输入所有可能取值的集合

输出空间：输出所有可能取值的集合

实例（instance）：每个具体的输入

实例通常由特征向量（feature vector）表示

特征空间（feature space）：所有特征向量存在的空间

训练集通常表示为：

$$
T
=\{(\vec{x}_1,y_1),(\vec{x}_2,y_2),\cdots,(\vec{x}_N,y_N) \}
$$

样本（sample）：输入与输出对

假设空间：从输入空间到输出空间的映射的集合

监督学习分为学习和预测两个过程。在学习过程中，学习系统通过给定的训练数据集。通过学习得到一个模型，表示为条件概率分布 $f_{Y|X}(y|\vec{x})$ 或决策函数 $\hat{f}(\vec{x})$；在预测过程中，预测系统对于给定的测试样本集中的输入 $\vec{x}_{N+1}$，由模型 $y_{N+1}=\argmax\limits_{y}f_{Y|X}(y|\vec{x}_{N+1})$ 或 $y_{N+1}=\hat{f}(\vec{x})$ 给出。在监督学习中，假设训练数据与测试数据是依联合概率分布 $f(\vec{x},y)$ 独立同分布产生的。

### 无监督学习（unsupervised learning）

设 $\mathcal{X}$ 是输入空间，$\mathcal{Z}$ 是隐式结构空间，要学习的模型可以表示为函数 $z=g(\vec{x})$，条件概率分布 $f_{Z|X}(z|\vec{x})$ 或条件概率分布 $f_{X|Z}(\vec{x}|z)$，其中，$\vec{x} \in \mathcal{X}$ 是输入，$z \in \mathcal{Z}$ 是 输出。无监督学习旨在从假设空间中选出在给定标准下的最优模型。

在学习过程中，学习系统从训练数据集学习，得到一个最优模型，表示为函数 $z=\hat{g}(\vec{x})$，条件概率分布 $f_{Z|X}(z|\vec{x})$ 或条件概率分布 $f_{X|Z}(\vec{x}|z)$；在预测过程中，预测系统对于给定的输入 $\vec{x}_{N+1}$，由模型 $z_{N+1}=\hat{g}(\vec{x}_{N+1})$ 或 $z_{N+1}=\argmax\limits_{z}f_{Z|X}(z|\vec{x}_{N+1})$ 给出相应的输出 $z_{N+1}$，进行聚类和降维，或者由模型 $f_{X|Z}(\vec{x}|z)$ 给出输入的条件概率密度 $f_{X|Z}(\vec{x}_{N+1}|z_{N+1})$，进行概率估计。

### 强化学习（reinforcement learning）

强化学习是指智能系统在与环境的连续互动中学习最优化行为策略的机器学习问题。

在每一步 $t$，智能系统从环境中观测到一个状态（state）$s_t$ 与一个奖励（reward）$r_t$，采取一个行动（action）$a_t$。环境根据智能系统选择的动作 $a_t$，决定下一步 $t+1$ 的的状态 $s_{t+1}$ 与奖励 $r_{t+1}$。要学习的策略表示为给定的状态下采取的动作。智能系统的目标是长期积累奖励的最大化。强化学习过程中，系统不断试错，以达到学习最优策略的目的。

强化学习的马尔可夫决策过程是状态、奖励、动作序列上的随机过程，由五元组 $\langle S,A,p,r,\gamma \rangle$ 组成。

$S$ 是有限状态（state）的集合

$A$ 是有限动作（action）的集合

$p$ 是状态转移概率（transition probability）函数，其定义为：

$$
p(s'|s,a)
=P(s_{t+1}=s'|s_t=s,a_t=a)
$$

r 是奖励函数（reward function），其定义为：

$$
r(s,a)
=E(r_{t+1}|s_t=s,a_t=a)
$$

$\gamma$ 是衰减系数，$\gamma \in [0,1]$

马尔可夫决策过程具有马尔可夫性，某个状态 $s_{t+1}$ 只依赖于前一个状态 $s_t$ 和动作 $a_t$，由状态转移概率函数 $p(s'|s,a)$ 表示；某个奖励 $r_{t+1}$ 只依赖于前一个状态 $s_t$ 和动作 $a_t$，由奖励函数 $r(s,a)$ 表示。

策略 $\pi$ 定义为，给定状态下动作的函数 $s=f(a)$ 或者条件概率密度 $f(a|s)$，给定一个策略 $\pi$，智能系统与环境互动的行为就已经确定。

价值函数（value function）或状态价值函数（state value function），定义为策略 $\pi$  从某一状态 $s$ 开始的长期积累奖励的数学期望：

$$
v_{\pi}(s)
=E_{\pi}(r_{t+1}+\gamma r_{t+2}+\gamma^2 t_{t+3}+\cdots|s_t=s)
$$

动作价值函数（action value function）定义为策略 $\pi$ 的从某一个状态 $s$  和动作 $a$ 开始的长期积累奖励的数学期望：

$$
q_{\pi}(s,a)
=E_{\pi}(r_{t+1}+\gamma r_{t+2}+\gamma^2 r_{t+2}+\cdots|s_t=s,a_t=a)
$$

强化学习的目标就是在所有可能的策略中选出价值函数最大的策略 $\pi^*$

### 半监督学习与主动学习

风险函数（risk function）或期望损失（expecte loss），定义为损失函数的期望，即：

$$
R_{exp}(f)
=E(L(Y,f(X)))
=\int\limits_{\mathcal{X}\times\mathcal{Y}} L(y,f(x)) f(x,y)\mathrm{d}x\mathrm{d}y
$$

学习的目标就是选择期望风险最小的模型

给定一个训练数据集

$$
T:\{(\vec{x}_1,y_1),(\vec{x}_2,y_2),\cdots,(\vec{x}_N,y_N) \}
$$

，经验风险（empirical risk）定义为：

$$
R_{emp}(f)
=\frac{1}{N}\sum\limits_{i=1}^{N}L(y_i,f(\vec{x}_i))
$$

经验风险最小化（empirical risk minimization，ERM）认为，经验风险最小的模型是最优的模型。按照经验风险最小化求最优模型

结构风险最小化

# 感知机



# k近邻法

k近邻法(k-nearest neighbor,k-NN)

$L_p$距离($L_p$ distance):设 $\chi$ 是 $n$ 维实数向量空间 $\mathbb{R}^n,x_i,x_j\in \chi,x_i=(x_i^{(1)},x_i^{(2)},\cdots,x_i^{(n)})^\mathrm{T},x_j=$,则$x_i,x_j$的$L_p$距离定义为：

$$
L_p(x_i,x_j)
=\bigg(\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)} |^p \bigg)^\frac{1}{p}
$$

两种特殊情况：

当$p=1,$

$$
L_1(x_i,x_j)
=\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)} |
$$

$L_1$称为曼哈顿距离(Manhattan distance)

当$p=2,$

$$
L_2(x_i,x_j)
=\bigg(\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)} |^2 \bigg)^\frac{1}{2}
$$

$L_2$称为欧氏距离(Euclidean distance)


当$p=\infty,$

$$
L_\infty(x_i,x_j)
=\max_l{|x_i^{(l)}-x_j^{(l)} |}
$$

对$p=\infty$时，$L_p$表达式的证明(太麻烦了，懒得打了)：

由$L_p$距离定义：

$$

\begin{aligned}

L_\infty(x_i,x_j)
&=\lim_{p \to \infty}L_p(x_i,x_j) \\
&=\lim_{p \to \infty}\bigg(\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)} |^p \bigg)^\frac{1}{p} \\
&=\lim_{p \to \infty}

\end{aligned}

$$


# 朴素贝叶斯法

## 基本方法

设输入空间 $\mathcal{X}\subseteq \mathbb{R}^n $ 为 $n$ 维向量的集合，输出空间为类标记集合 $\mathcal{Y}=\{c_1,c_2,\cdots,c_K \}. $ 输入为特征向量 $\vec{x}\in\mathcal{X} ,$ 输出为类标记 $y\in\mathcal{Y}. $ $X$ 是定义在输入空间 $\mathcal{X} $ 上的随机向量，$Y$ 是定义在输出空间 $\mathcal{Y}$ 上的随机变量. $P(X,Y)$ 是 $X,Y$ 的联合概率分布.

设训练数据集：

$$
T=\{(\vec{x}_1,y_1),(\vec{x}_2,y_2),\cdots,(\vec{x}_N,y_N) \}
$$

由 $P(X,Y)$ 独立同分布产生.

朴素贝叶斯法通过数据集 $T$ 学习联合概率分布 $P(X,Y)$

具体来说，学习以下先验概率分布及条件概率分布：

先验概率分布：

$$
P(Y=c_k),~~~k=1,2,\cdots,K
$$

条件概率分布：

$$
P(X=\vec{x}|Y=c_k)
=P( X^{(1)}=\vec{x}^{(1)},X^{(2)}=\vec{x}^{(2)},\cdots,X^{(n)}=\vec{x}^{(n)} | Y=c_k )
$$

由条件概率公式：

$$
P(X=\vec{x},Y=c_k)=P(Y=c_k)P(X=\vec{x} | Y=c_k)
$$

就学习到了联合概率分布 $P(X,Y)$

朴素贝叶斯法对条件概率分布作了条件独立性的假设，即:

$$

\begin{align}

P(X=\vec{x}|Y=c_k)
&\equiv P(X^{(1)}=\vec{x}^{(1)},\cdots,X^{(n)}=\vec{x}^{(n)}|Y=c_k) \\
&=\prod_{j=1}^n P(X^{(j)}=\vec{x}^{(j)}|Y=c_k) 

\end{align}

$$

朴素贝叶斯法进行分类时，对给定的输入 $\vec{x},$ 通过学习到的模型计算后验概率分布：$P(Y=c_k|X=\vec{x});$而由贝叶斯定理(条件概率公式+全概率公式)，有：

$$
P(Y=c_k|X=\vec{x})
=\frac{P(X=\vec{x},Y=c_k)}{P(X=\vec{x})}
=\frac{P(Y=c_k)P(X=\vec{x}|Y=c_k)}{\sum\limits_{i} P(Y=c_i)P(X=\vec{x}|Y=c_i)}
$$

把(2)代入上式，进一步有：

$$
P(Y=c_k|X=\vec{x})
=\frac{P(Y=c_k)\prod\limits_{j}^n P(X^{(j)}=\vec{x}^{(j)}|Y=c_k) }{\sum\limits_{i}P(Y=c_i)\prod\limits_{j}P(X^{(j)}=\vec{x}^{(j)}|Y=c_i)} ,~~~k=1,2,\cdots,K
$$

于是朴素贝叶斯分类器可表示为：

$$
\hat{y}
=f(\vec{x})
=\argmax_{c_k}P(Y=c_k|X=\vec{x})
=\argmax_{c_k}\frac{P(Y=c_k)\prod\limits_{j} P(X^{(j)}=\vec{x}^{(j)}|Y=c_k) }{\sum\limits_{i}P(Y=c_i)\prod\limits_{j}P(X^{(j)}=\vec{x}^{(j)}|Y=c_i)}
$$

注意到，上式中，对所有的 $c_k,$ 分母的值都是相同的，于是,朴素贝叶斯分类器可进一步简化为：

$$
\hat{y}
=\argmax_{c_k}P(Y=c_k)\prod\limits_{j} P(X^{(j)}=\vec{x}^{(j)}|Y=c_k) 
$$

### 后验概率最大化

朴素贝叶斯把实例分到后验概率最大的类中，这等价于期望风险最小化.

把实例分到后验概率最大的类所对应的分类决策函数 $f:$

$$
f(\vec{x})
=\argmax_{y\in\mathcal{Y}}P(Y=y|X=\vec{x})
$$

下面证明，期望风险最小化等价于后验概率最大化.

假设选择$0-1$ 损失函数：

$$
L(Y,f(X))
=

\begin{cases}

1&,Y\ne f(X) \\
0&,Y=f(X)

\end{cases}

$$

设有一组 $(\vec{x},y) ,$ 其中，$\vec{x} $ 是输入的特征向量，$y$ 是与之对应的标签. 设 $\mathcal{F}$ 是假设空间，我们希望找到一个函数 $f\in \mathcal{F},$ 使得在此函数的作用下，输出的预测值 $f(\vec{x})$ 等于或尽可能接近标签 $y $. 我们选择用“期望风险最小”来描述这种“尽可能接近”：


$$

\begin{aligned}

R_{\exp}(f)
&=E[L(Y,f(X))] \\
&=\sum_{i}\sum_{k} L(c_k,f(\vec{x}_i))\cdot P(Y=c_k,X=\vec{x}_i) \\
&=\sum_{k}\sum_{i } L(c_k,f(\vec{x}_i))\cdot P(Y=c_k,X=\vec{x}_i) \\

\end{aligned}

$$


```
期望风险最小就是说，分类决策函数 $f$ 应当输出使得期望风险函数最小的  $y,$即：
```


$$
f(\vec{x})
=\argmin_{y\in\mathcal{Y}} \sum_{k=1}^{K} L(c_k,y)P(Y=c_k|X=\vec{x})
$$

```
其中，$f(X)$ 是分类决策函数. 这时，期望风险函数为：

$$

\begin{aligned}

R_{\exp}(f)
&=E[L(Y,f(X))] \\
&=\sum_{i}\sum_{k} L(c_k,\vec{x}_i)\cdot P(Y=c_k,X=\vec{x}_i) \\
&=\sum_{i}\sum_{k} L(c_k,\vec{x}_i)\cdot P(Y=c_k,X=\vec{x}_i) \\

\end{aligned}

$$
```

### 朴素贝叶斯的参数估计

极大似然估计：

在朴素贝叶斯法中，学习意味着估计 $P(Y=c_k)$ 和 $P(X^{(j)}=x^{(j)}|Y=c_k)$

先验概率 $P(Y=c_k)$ 的极大似然估计是：

$$
P(Y=c_k)
=\frac{\sum\limits_{i=1}^N I(y_i=c_k)}{N},~~~k=1,2,\cdots,K
$$

设第 $j$ 个特征 $\vec{x}^{(j)} $ 可能取值的集合为 $\{a_{j1},a_{j2},\cdots,a_{jS_j} \},$ 条件概率 $P(X^{(j)}=a_{jl}|Y=c_k) $ 的极大似然估计是：

$$
P(X^{(j)}=a_{jl}|Y=c_k)
=\frac{P(X^{(j)}=a_{jl},Y=c_k)}{P(Y=c_k)}
=\frac{\sum\limits_{i=1}^N I(\vec{x}_i^{(j)}=a_{jl},y_i=c_k) /N}{\sum\limits_{i=1}^{N} I(y_i=c_k)/N}
=\frac{\sum\limits_{i=1}^{N} I(\vec{x}_i^{(j)}=a_{jl},y_i=c_k) }{\sum\limits_{i=1}^N I(y_i=c_k)}
$$

$$
j=1,2,\cdots,n;~~~l=1,2,\cdots,S_j;~~~k=1,2,\cdots,K
$$

式中，$\vec{x}_i^{(j)} $ 是第 $i$ 个样本的输入 $\vec{x}_i$ 的第 $j$ 个特征；$a_{jl}$ 是第 $j$ 个特征可能取的第 $l$ 个值；$I$ 为指示函数.

朴素贝叶斯算法(naive Vayes algorithm)

输入：训练数据 $T= \{(\vec{x}_1,y_1),(\vec{x}_2,y_2),\cdots,(\vec{x}_N,y_N) \},$ 其中 $\vec{x}_i=(\vec{x}_i^{(1)},\vec{x}_i^{(2)},\cdots,\vec{x}_i^{(N)})^{\mathrm{T}},$ $\vec{x}_i^{(j)}$ 是第 $i$ 个样本的输入 $\vec{x}_i $ 的第 $j$ 个特征. $\vec{x}_i^{(j)} \in \{a_{j1},a_{j2},\cdots,a_{jS_j} \} ,$ $a_{jl}$ 是第 $j$ 个特征可能取得第 $l$ 个值，$j=1,2,\cdots,n;l=1,2,\cdots,S_j;y_i\in \{c_1,c_2,\cdots,c_K \};$ 实例 $\vec{x}$ 

输出：实例 $\vec{x}$ 的分类

(1)计算先验概率及条件概率

$$
P(Y=c_k)
=\frac{\sum\limits_{i=1}^N I(y_i=c_k)}{N},~~~k=1,2,\cdots,K
$$

$$
P(X^{(j)}=a_{jl}|Y=c_k)
=\frac{\sum\limits_{i=1}^N I(\vec{x}_i^{(j)}=a_{jl},y_i=c_k)}{\sum\limits_{i=1}^N I(y_i=c_k)}
$$

$$
j=1,2,\cdots,n;~~~l=1,2,\cdots,S_j;~~~k=1,2,\cdots K
$$

(2)对于给定的实例 $\vec{x}=(\vec{x}^{(1)},\vec{x}^{(2)},\cdots,\vec{x}^{(n)})^{\mathrm{T}}, $ 计算：

$$
P(Y=c_k)\prod_{j=1}^{n} P(X^{(j)}=\vec{x}^{(j)}|Y=c_k),~~~k=1,2,\cdots,K
$$

(3)确定实例 $\vec{x}$ 的类：

$$
y=\argmax_{c_k} P(Y=c_k)\prod_{j=1}^{n} P(X^{(j)}=\vec{x}^{(j)}|Y=c_k)
$$

例：

试从下表给定的训练数据学习一个朴素贝叶斯分类器，并确定 $\vec{x}=(2,S)^{\mathrm{T}} $ 的类标记 $y.$ 表中，$X^{(1)},X^{(2)}$ 为特征，取值的集合分别为 $A_1=\{1,2,3 \} ,A_2=\{S,M,L \},$ $Y$ 为标记类，$Y\in C=\{1,-1 \}$ 

|训练数据编号|1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
|$X^{(1)}$ |1|1|1|1|1|2|2|2|2|2|3|3|3|3|3|
|$X^{(2)}$ |S|M|M|S|S|S|M|M|L|L|L|M|M|L|L|
|$Y$ |-1|-1|1|1|-1|-1|-1|1|1|1|1|1|1|1|-1|

根据朴素贝叶斯算法:

(1):

$$
P(Y=1)=\frac{9}{15}
$$

$$
P(Y=-1)=\frac{6}{15}
$$

$$
P(X^{(1)}=1 |Y=1)=\frac{2}{9},
P(X^{(1)}=2 |Y=1)=\frac{3}{9},
P(X^{(1)}=3 |Y=1)=\frac{4}{9}
$$

$$
P(X^{(2)}=S |Y=1)=\frac{1}{9},
P(X^{(2)}=M |Y=1)=\frac{4}{9},
P(X^{(2)}=L |Y=1)=\frac{4}{9}
$$



$$
P(X^{(1)}=1 |Y=-1)=\frac{3}{6},
P(X^{(1)}=2 |Y=-1)=\frac{2}{6},
P(X^{(1)}=3 |Y=-1)=\frac{1}{6}
$$

$$
P(X^{(2)}=S |Y=-1)=\frac{3}{6},
P(X^{(2)}=M |Y=-1)=\frac{2}{6},
P(X^{(2)}=L |Y=-1)=\frac{1}{6}
$$

对于给定的实例 $\vec{x}=(2,S)^{\mathrm{T}}, $计算：

$$
P(Y=1)P(X^{(1)}=2|Y=1)P(X^{(2)}=S|Y=1)
=\frac{9}{15}\cdot\frac{3}{9}\cdot\frac{1}{9}
=\frac{1}{45}
$$

$$
P(Y=-1)P(X^{(1)}=2|Y=-1)P(X^{(2)}=S|Y=-1)
=\frac{6}{15}\cdot\frac{2}{6}\cdot\frac{3}{6}
=\frac{1}{15}
$$

由于 $P(Y=-1)P(X^{(1)}=2|Y=-1)P(X^{(2)}=S|Y=-1)$ 最大，所以 $y=-1$

### 贝叶斯估计

用极大似然估计可能会出现所要估计的概率值为 $0$ 的情况，这时会影响到后验概率的计算结果，使分类产生偏差。为了解决这一问题，我们采用贝叶斯估计。

条件概率的贝叶斯估计是：

$$
P_{\lambda}(X^{(j)}=a_{jl}|Y=c_k)
=\frac{\lambda+\sum\limits_{i=1}^{N} I(\vec{x}_i^{(j)}=a_{jl},y_i=c_k) }{S_j\lambda+\sum\limits_{i=1}^{N} I(y_i=c_k) }
$$

式中，$\lambda\geqslant 0.$贝叶斯估计就是说，在随机变量各个取值的频数上赋予一个正数 $\lambda>0.$ 当 $\lambda=0$ 时就是极大似然估计. 常取 $\lambda=1,$ 这时称为拉普拉斯平滑(Laplacian smoothing). 对任何 $l=1,2,\cdots,S_j;k=1,2,\cdots,K,$ 有：

$$
P_{\lambda}(X^{(j)}=a_{jl}=Y=c_k)>0
$$

$$
\sum_{l=1}^{S_j} P(X^{(j)}=a_{jl}|Y=c_k) =1
$$

上面两式表明，条件概率的贝叶斯估计确实是一种概率分布.

例：

对同样的表，按照拉普拉斯平滑估计概率，即取 $\lambda=1.$

解：

计算概率：

$$
P(Y=1)=\frac{10}{17}
$$

$$
P(Y=-1)=\frac{7}{17}
$$

$$
P(X^{(1)}=1 |Y=1)=\frac{3}{12},
P(X^{(1)}=2 |Y=1)=\frac{4}{12},
P(X^{(1)}=3 |Y=1)=\frac{5}{12}
$$

$$
P(X^{(2)}=S |Y=1)=\frac{2}{12},
P(X^{(2)}=M |Y=1)=\frac{5}{12},
P(X^{(2)}=L |Y=1)=\frac{5}{12}
$$



$$
P(X^{(1)}=1 |Y=-1)=\frac{4}{9},
P(X^{(1)}=2 |Y=-1)=\frac{3}{9},
P(X^{(1)}=3 |Y=-1)=\frac{2}{9}
$$

$$
P(X^{(2)}=S |Y=-1)=\frac{4}{9},
P(X^{(2)}=M |Y=-1)=\frac{3}{9},
P(X^{(2)}=L |Y=-1)=\frac{2}{9}
$$

对于给定的实例 $\vec{x}=(2,S)^{\mathrm{T}}, $计算：

$$
P(Y=1)P(X^{(1)}=2|Y=1)P(X^{(2)}=S|Y=1)
=\frac{10}{17}\cdot\frac{4}{12}\cdot\frac{2}{12}
=\frac{5}{153}
\approx 0.0327
$$

$$
P(Y=-1)P(X^{(1)}=2|Y=-1)P(X^{(2)}=S|Y=-1)
=\frac{7}{17}\cdot\frac{3}{9}\cdot\frac{4}{9}
=\frac{28}{459}
\approx 0.0610
$$

由于 $0.0327<00.0610,$于是 $\hat{y}=-1$

# 决策树

决策树的定义：分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点（node）和有向边（directed edge）组成。结点有两种类型：内部结点（internal node）和叶节点（leaf node）。内部结点表示一个特征或属性，叶节点表示一个类。

用决策树分类，从根结点开始，对实例的某一特征进行测试，根据测试结果，将实例分配到其子结点；这时，每一个子结点对应着该特征的一个取值。如此递归地对实例进行测试并分配，直至达到叶结点。最后将实例分到叶结点地类中。

## 决策树与 if-then 规则

可以将决策树看成一个 if-then 规则的集合。

## 决策树学习

假设给定训练数据集：

$$
D=\{(\vec{x}_1,y_1),(\vec{x}_2,y_2),\cdots,(\vec{x}_N,y_N) \}
$$

其中，$\vec{x}_i=(\vec{x}_i^{(1)},\vec{x}_i^{(2)},\cdots,\vec{x}_i^{(n)})^{\mathrm{T}} $ 为输入实例（特征向量，）$n$ 为特征个数，$y_i\in \{1,2,\cdots,K\}$ 为类标记，$i=1,2,\cdots,N,N$ 为样本容量。决策树学习的目标是根据给定的训练数据集构建一个决策树模型，使它能够对实例进行正确的分类。

决策树学习用损失函数表示这一目标。决策树学习的损失函数通常是正则化的极大似然函数。决策树学习的策略是以损失函数为目标的最小化。

### 熵与条件熵

在信息论与概率统计中，熵（entropy）是表示随机变量不确定性的的度量。设 $X$ 是一个取有限个值得离散随机变量，其概率分布为：

$$
P(X=x_i)
=p_i,~~~i=1,2,\cdots,n
$$

则随机变量 $X$ 的熵的定义为：

$$
H(X)
=-\sum_{i=1}^n p_i\log p_i
$$

规定，若 $p_i=0,$ 则 $p_i\log p_i=0.$ 通常，对数的底取 $2$ 或 $e,$这时 熵的单位分别称为比特（bit）或纳特（nat）。显然，熵只依赖于 $X$ 的分布，而与 $X$ 的取值无关，所以也可将 $X$ 的熵记作 $H(p),$即：

$$
H(p)
=-\sum_{i=1}^{n} p_i\log p_i
$$

熵越大，随机变量的不确定性就越大。

熵的性质：

$$
-\leqslant H(p)\leqslant \log n
$$

设有二维随机变量 $(X,Y),$ 其联合分布律为：

$$
P(X=x_i,Y=y_i)=p_{ij},~~~i=1,2,\cdots;~~~j=1,2,\cdots,m
$$

条件熵 $H(Y|X)$ 表示在随机变量 $X$ 的取值已知的条件下随机变量 $Y$ 的不确定性。随机变量 $X$ 给定的条件下，随机变量 $Y$ 的条件熵（conditional entropy）$H(Y|X)$，定义为 $X$ 给定的条件下，$Y$ 的条件概率分布的熵对 $X$ 的数学期望：

$$
H(Y|X)
=\sum_{i=1}^{n} p_i H(Y|X=x_i)
$$

这里，$p_i=P(X=x_i),i=1,2,\cdots,n$

当熵和条件熵中的概率由数据估计（特别是极大似然估计）得到时，所对应的熵与条件熵分别称为经验熵（empirical entropy）和经验条件熵（empirical conditional entropy）。此时，若

# PR&ML



